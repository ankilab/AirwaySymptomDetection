{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43556c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "\n",
    "import flammkuchen as fl\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import copy\n",
    "from nutil.plot import paperStyle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from neural_networks.src.dataloader import DataLoader\n",
    "from utils.params import Params\n",
    "from analysis.src.conf_matrices import generate_confusion_matrix\n",
    "from neural_networks.src.lr_scheduler import exp_scheduler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97303ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = r\"../../Data/New_Data/\"\n",
    "PATH_GA_MODEL_NSA = r\"../neural_networks/GeneticAlgorithm/Results_GA/GA_20211115-105541_objective2/best_models_per_generation/gen17_Fitness2.4656.hdf5\"\n",
    "\n",
    "PATH_PARAMS = r\"../neural_networks/params.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(PATH_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6ce54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params.signal_type = 'NSA'\n",
    "data_loader = DataLoader(params=params, nb_classes=4)\n",
    "(X_train_new_dataset, Y_train_new_dataset), (X_test_new_dataset, Y_test_new_dataset) = data_loader.get_mcgill_new_data(PATH_DATA, without_no_event=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ga = load_model(PATH_GA_MODEL_NSA, custom_objects={'leaky_relu': tf.nn.leaky_relu, 'relu6': tf.nn.relu6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ga.evaluate(X_test_new_dataset[..., None], Y_test_new_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train_old, Y_train_old), (X_val_old, Y_val_old) = data_loader.get_train_val_data()\n",
    "X_test_old, Y_test_old = data_loader.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fine_tune_model(X, Y):\n",
    "    model_ga = load_model(PATH_GA_MODEL_NSA, custom_objects={'leaky_relu': tf.nn.leaky_relu, 'relu6': tf.nn.relu6})\n",
    "    fine_tuned_model = model_ga\n",
    "    fine_tuned_model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "    \n",
    "    test_accs_old = []\n",
    "    test_accs_new = []\n",
    "    \n",
    "    class_weight = None\n",
    "    \n",
    "    n_epochs = 100\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch == 70:\n",
    "            # after epoch 70 the learning rate is reduced\n",
    "            fine_tuned_model.compile(optimizer=tf.keras.optimizers.Adam(0.00001), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "        history = fine_tuned_model.fit(X_[..., None], Y_, \n",
    "                                     shuffle=True, \n",
    "                                     epochs=1,\n",
    "                                     batch_size=256,\n",
    "                                     class_weight=class_weight,\n",
    "                                     verbose=False)\n",
    "        \n",
    "        # calculate test accuracies after each epoch\n",
    "        test_accs_old.append(fine_tuned_model.evaluate(X_test_old[..., None], Y_test_old)[1])\n",
    "        test_accs_new.append(fine_tuned_model.evaluate(X_test_new_dataset[..., None], Y_test_new_dataset)[1])\n",
    "        \n",
    "    return test_accs_old, test_accs_new\n",
    "\n",
    "def get_class_weights(Y_train):\n",
    "    y_train = []\n",
    "    for y in Y_train:\n",
    "        y_train.append(int(np.where(y == 1)[0]) + 1)\n",
    "    y_train.append(4) # append one 4 in case there is no \"no event\" in the list\n",
    "    y_train = np.array(y_train)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=[1, 2, 3, 4], y=y_train)\n",
    "    class_weights = {0: class_weights[0],\n",
    "                     1: class_weights[1],\n",
    "                     2: class_weights[2],\n",
    "                     3: class_weights[3]}\n",
    "    print(f\"Using class weights: {class_weights}\")\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning with old and new dataset combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.array([*X_train_old, *X_train_new_dataset])\n",
    "Y_ = np.array([*Y_train_old, *Y_train_new_dataset])\n",
    "\n",
    "test_accs_old_1, test_accs_new_1 = fine_tune_model(X_, Y_)\n",
    "\n",
    "plt.plot(test_accs_old_1, label=\"old test accs\")\n",
    "plt.plot(test_accs_new_1, label=\"new test accs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning only with new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_ = np.array(X_train_new_dataset)\n",
    "Y_ = np.array(Y_train_new_dataset)\n",
    "\n",
    "test_accs_old_2, test_accs_new_2 = fine_tune_model(X_, Y_)\n",
    "\n",
    "plt.plot(test_accs_old_2, label=\"old test accs\")\n",
    "plt.plot(test_accs_new_2, label=\"new test accs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions using 'flammkuchen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(test_accs_old_1=test_accs_old_1, test_accs_new_1=test_accs_new_1, test_accs_old_2=test_accs_old_2, test_accs_new_2=test_accs_new_2)\n",
    "fl.save(\"fine_tuning_new_dataset.vfp\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
